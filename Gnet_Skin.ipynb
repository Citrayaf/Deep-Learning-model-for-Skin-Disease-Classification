{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "VVVvf1enqTo4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "94dvuaFhp_7_"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive', force_remount=True) #Link ke gdrive\n",
        "\n",
        "import sys\n",
        "sys.path.append('/content/gdrive/My Drive') #File dari gdrive ke colab\n",
        "\n",
        "import os\n",
        "os.chdir('/content/gdrive/My Drive') #working directory menjadi /content/gdrive/My Drive "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "pAwvrCz5qWvj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def unique(list1):\n",
        "    unique_list = [] #array kosong\n",
        "     \n",
        "    for x in list1:  #looping \n",
        "        if x not in unique_list: #Cek apakah ada data yang berulang atau tidak\n",
        "            unique_list.append(x)\n",
        "    return unique_list"
      ],
      "metadata": {
        "id": "MCwZ0XbGqS1r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from PIL import Image\n",
        "from imutils import paths\n",
        "\n",
        "\n",
        "kumpl_gmbr = [] #dataset gambar\n",
        "kumpl_lbl = [] #label dataset\n",
        "imgpths = paths.list_images('Dataset') #path untuk mengambil dataset\n",
        "\n",
        "for dirimg in imgpths: #looping gambar\n",
        "  gmbr = Image.open(dirimg)\n",
        "  gmbrz = np.array(gmbr.resize((224,224))) / 255.0 #resize + normalisasi\n",
        "  kumpl_gmbr.append(gmbrz) #memasukkan dataset yang sudah diolah ke variabel\n",
        "\n",
        "  lbl_kls = dirimg.split(os.path.sep) [-2] #pengambilan label\n",
        "  kumpl_lbl.append(lbl_kls) #mengumpulkan label ke variabel\n",
        "  \n",
        "kelas_asli = unique(kumpl_lbl)\n",
        "kelas_asli"
      ],
      "metadata": {
        "id": "UIxe-WOtqZZb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelBinarizer\n",
        "\n",
        "lb = LabelBinarizer() #function untuk mengubah variabel label menjadi bentuk binary\n",
        "kumpl_lbl = lb.fit_transform(kumpl_lbl) #proses pengubahan\n",
        "#if len(kelas_asli)==2: \n",
        "#  kumpl_lbl = np.hstack((kumpl_lbl, 1 - kumpl_lbl))"
      ],
      "metadata": {
        "id": "nsAiuCVcrWat"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "ratio_latih = 0.8 #ratio data latih\n",
        "ratio_uji = 0.2 #ratio data uji\n",
        " \n",
        "(latihX, ujiX, latihY, ujiY) = train_test_split(np.array(kumpl_gmbr),np.array(kumpl_lbl), test_size=ratio_uji) #Proses pemisahan, test_size menentukan banyaknya data uji\n",
        "\n",
        "print(latihX.shape)\n",
        "print(latihY.shape)\n",
        "print(ujiX.shape)\n",
        "print(ujiY.shape)\n"
      ],
      "metadata": {
        "id": "JC8rG6PsrjCo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "RcZG7g_GsDjL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "datagen = ImageDataGenerator(\n",
        "      rotation_range=40,\n",
        "      width_shift_range=0.2,\n",
        "      height_shift_range=0.2,\n",
        "      shear_range=0.2,\n",
        "      zoom_range=0.2,\n",
        "      horizontal_flip=True,\n",
        "      fill_mode='nearest')"
      ],
      "metadata": {
        "id": "wsQSsFa_sAfD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "AksZ_iHGsL7J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "i=0\n",
        "banyak_lth=latihX.shape\n",
        "aug=[]\n",
        "for jj in range(banyak_lth[0]):\n",
        "  x = latihX[jj]\n",
        "  x = x.reshape((1,) + x.shape)  #Penambahan dimensi agar bisa diaugmentasi\n",
        "\n",
        "  for aug in datagen.flow(x, batch_size=1): #proses augmentasi, memasukkan gambar ke function augmentasi\n",
        "      latihX = np.append(latihX, aug ,axis=0)\n",
        "      label = latihY[jj]  #Pengambilan label untuk data augmentasi\n",
        "      label = label.reshape((1,) + label.shape) \n",
        "      latihY = np.append(latihY, label,axis=0)  #Memasukkan label data augment ke variabel label\n",
        "      if i == 1:\n",
        "        break \n",
        "      i += 1"
      ],
      "metadata": {
        "id": "vadnIgO5sMcC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pembentukkan Model ResNet"
      ],
      "metadata": {
        "id": "oa1r-GJIs1rX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Library\n",
        "from keras.layers import Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPooling2D\n",
        "from keras.initializers import glorot_uniform\n",
        "from keras.models import Model"
      ],
      "metadata": {
        "id": "eghmUuTSuI-e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Deklarasi Function"
      ],
      "metadata": {
        "id": "zzmauiRYs4B5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import keras\n",
        "from keras.layers import BatchNormalization\n",
        "from keras.layers.convolutional import Conv2D\n",
        "from keras.layers.convolutional import MaxPooling2D\n",
        "from keras.layers.convolutional import AveragePooling2D\n",
        "from keras.layers.core import Dense\n",
        "from keras.layers.core import Activation\n",
        "from keras.layers.core import Dropout\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Input\n",
        "from keras.layers import concatenate\n",
        "from keras.models import Model\n",
        "from keras.regularizers import l2\n",
        "from keras import backend as K\n",
        "\n",
        "class GoogLeNet:\n",
        "    @staticmethod\n",
        "    def conv_module(x, K, kX, kY, stride, chanDim,\n",
        "        padding = \"same\", reg = 0.0005, name = None):\n",
        "        # initialize the CONV, BN, and RELU layer names\n",
        "        (convName, bnName, actName) = (None, None, None)\n",
        "\n",
        "        # if a layer name was supplied, prepend it\n",
        "        if name is not None:\n",
        "            convName = name + \"_conv\"\n",
        "            bnName = name + \"_bn\"\n",
        "            actName = name + \"_act\"\n",
        "\n",
        "        # define a CONV => BN => RELU pattern\n",
        "        x = Conv2D(K, (kX, kY), strides = stride, padding = padding,\n",
        "            kernel_regularizer = l2(reg), name = convName)(x)\n",
        "        x = BatchNormalization(axis = chanDim, name = bnName)(x)\n",
        "        x = Activation(\"relu\", name = actName)(x)\n",
        "\n",
        "        # return the block\n",
        "        return x\n",
        "\n",
        "    @staticmethod\n",
        "    def inception_module(x, num1x1, num3x3Reduce, num3x3, num5x5Reduce,\n",
        "        num5x5, num1x1Proj, chanDim, stage, reg = 0.0005):\n",
        "        # define the first branch of the Inception module which\n",
        "        # consists of 1x1 convolutions\n",
        "        first = GoogLeNet.conv_module(x, num1x1, 1, 1, (1, 1),\n",
        "            chanDim, reg = reg, name = stage + \"_first\")\n",
        "\n",
        "        # define the second branch of the Inception module which\n",
        "        # consists of 1x1 and 3x3 convolutions\n",
        "        second = GoogLeNet.conv_module(x, num3x3Reduce, 1, 1, (1, 1),\n",
        "            chanDim, reg = reg, name = stage + \"_second1\")\n",
        "        second = GoogLeNet.conv_module(second, num3x3, 3, 3, (1, 1),\n",
        "            chanDim, reg = reg, name = stage + \"_second2\")\n",
        "\n",
        "        # define the third branch of the Inception module which\n",
        "        # are both 1x1 and 5x5 convolutions\n",
        "        third = GoogLeNet.conv_module(x, num5x5Reduce, 1, 1, (1, 1),\n",
        "            chanDim, reg = reg, name = stage + \"_third1\")\n",
        "        third = GoogLeNet.conv_module(third, num5x5, 5, 5, (1, 1),\n",
        "            chanDim, reg = reg, name = stage + \"_third2\")\n",
        "\n",
        "        # define the fourth branch of the Inception module which\n",
        "        # is the POOL projection\n",
        "        fourth = MaxPooling2D((3, 3), strides = (1, 1), padding = \"same\",\n",
        "            name = stage + \"_pool\")(x)\n",
        "        fourth = GoogLeNet.conv_module(fourth, num1x1Proj, 1, 1, (1, 1),\n",
        "            chanDim, reg = reg, name = stage + \"_fourth\")\n",
        "\n",
        "        # concatenate across the channel dimension\n",
        "        x = concatenate([first, second, third, fourth], axis = chanDim,\n",
        "            name = stage + \"_mixed\")\n",
        "\n",
        "        # return the block\n",
        "        return x\n",
        "\n",
        "    @staticmethod\n",
        "    def build(width, height, depth, classes, reg = 0.0005):\n",
        "        # initialize the input shape to be \"channel last\" and the\n",
        "        # channels dimension itself\n",
        "        inputShape = (height, width, depth)\n",
        "        chanDim = -1\n",
        "\n",
        "        # if we are using \"channel first\", update the input shape\n",
        "        # and channels dimension\n",
        "        if K.image_data_format() == \"channels_first\":\n",
        "            inputShape = (depth, height, width)\n",
        "            chanDim = 1\n",
        "\n",
        "        # define the model input, followed by a sequence of\n",
        "        # CONV => POOL => (CONV * 2) => POOL layers\n",
        "        inputs = Input(shape = inputShape)\n",
        "        x = GoogLeNet.conv_module(inputs, 64, 5, 5, (1, 1),\n",
        "            chanDim, reg = reg, name = \"block1\")\n",
        "        x = MaxPooling2D((3, 3), strides = (2, 2), padding = \"same\",\n",
        "            name = \"pool1\")(x)\n",
        "        x = GoogLeNet.conv_module(x, 64, 1, 1, (1, 1),\n",
        "            chanDim, reg = reg, name = \"block2\")\n",
        "        x = GoogLeNet.conv_module(x, 192, 3, 3, (1, 1),\n",
        "            chanDim, reg = reg, name = \"block3\")\n",
        "        x = MaxPooling2D((3, 3), strides = (2, 2), padding = \"same\",\n",
        "            name = \"pool2\")(x)\n",
        "\n",
        "        # apply two Inception module followed by a POOL\n",
        "        x = GoogLeNet.inception_module(x, 64, 96, 128, 16, 32, 32,\n",
        "            chanDim, \"3a\", reg = reg)\n",
        "        x = GoogLeNet.inception_module(x, 128, 128, 192, 32, 96, 64,\n",
        "            chanDim, \"3b\", reg = reg)\n",
        "        x = MaxPooling2D((3, 3), strides = (2, 2), padding = \"same\",\n",
        "            name = \"pool3\")(x)\n",
        "\n",
        "        # apply five Inception module followed by POOL\n",
        "        x = GoogLeNet.inception_module(x, 192, 96, 208, 16, 48, 64,\n",
        "            chanDim, \"4a\", reg = reg)\n",
        "        x = GoogLeNet.inception_module(x, 160, 112, 224, 24, 64, 64,\n",
        "            chanDim, \"4b\", reg = reg)\n",
        "        x = GoogLeNet.inception_module(x, 128, 128, 256, 24, 64, 64,\n",
        "            chanDim, \"4c\", reg = reg)\n",
        "        x = GoogLeNet.inception_module(x, 112, 144, 288, 32, 64, 64,\n",
        "            chanDim, \"4d\", reg = reg)\n",
        "        x = GoogLeNet.inception_module(x, 256, 160, 320, 32, 128, 128,\n",
        "            chanDim, \"4e\", reg = reg)\n",
        "        x = MaxPooling2D((3, 3), strides = (2, 2), padding = \"same\",\n",
        "            name = \"pool4\")(x)\n",
        "\n",
        "        # apply last two Inception module\n",
        "        x = GoogLeNet.inception_module(x, 256, 160, 320, 32, 128, 128,\n",
        "            chanDim, \"5a\", reg = reg)\n",
        "        x = GoogLeNet.inception_module(x, 384, 192, 384, 48, 128, 128,\n",
        "            chanDim, \"5b\", reg = reg)\n",
        "\n",
        "        # apply a POOL layer (average) followed by dropout\n",
        "        x = AveragePooling2D((4, 4), name = \"pool5\")(x)\n",
        "        x = Dropout(0.4, name = \"do\")(x)\n",
        "\n",
        "        # softmax classifier\n",
        "        x = Flatten(name = \"flatten\")(x)\n",
        "        #x = layers.Dropout(0.5)(x)\n",
        "        x = Dense(classes, kernel_regularizer = l2(reg), name = \"labels\")(x)\n",
        "        x = Activation(\"softmax\", name = \"softmax\")(x)\n",
        "\n",
        "        # create the model\n",
        "        model = Model(inputs, x, name = \"googlenet\")\n",
        "\n",
        "        # return the constructed network architecture\n",
        "        return model"
      ],
      "metadata": {
        "id": "9Pm4oo4Vubjh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "GoogLeNet.build(width = 224, height = 224, depth = 3, classes = kelas_asli, reg = 0.0002)"
      ],
      "metadata": {
        "id": "Y5zSb6gewF9b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "12qPRnWJwSbs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.optimizers import SGD, Adam,  Nadam,  Adamax\n",
        "\n",
        "sgd = SGD(learning_rate=0.0015) \n",
        "adam = Adam(learning_rate=0.0015)\n",
        "nadam = Nadam(learning_rate=0.0015)\n",
        "adamax = Adamax(learning_rate=0.0015)"
      ],
      "metadata": {
        "id": "SJKDQTaAwYnt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "DdaVZXC2yY-Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "class myCallback(tf.keras.callbacks.Callback): \n",
        "    def on_epoch_end(self, epoch, logs={}): \n",
        "        if(logs.get('val_accuracy') > 0.9):   \n",
        "          print(\"\\nReached Target\")   \n",
        "          self.model.stop_training = True"
      ],
      "metadata": {
        "id": "r76Y9SIPyYIn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "GoogLeNet.compile(loss=\"categorical_crossentropy\", optimizer=adam, metrics=[\"accuracy\"])\n"
      ],
      "metadata": {
        "id": "5HGexF7Fwm5n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "buW9msN7ylsL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "callbacks = myCallback()\n",
        "history = GoogLeNet.fit(latihX, latihY,validation_data=(ujiX, ujiY), epochs = 55, batch_size = 32, callbacks=[callbacks]) #early stopping\n",
        "#history = ResNet.fit(latihX, latihY,validation_data=(ujiX, ujiY), epochs = 55, batch_size = 32) #tanpa early stopping"
      ],
      "metadata": {
        "id": "Uw_8tPckyzSU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#evaluasi\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "print(\"[INFO] evaluating network...\")\n",
        "predictions = ResNet.predict(ujiX, batch_size=32) \n",
        "print(classification_report(ujiY.argmax(axis=1), predictions.argmax(axis=1), target_names=lb.classes_))  "
      ],
      "metadata": {
        "id": "9IaFICU4y9qt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "B6m6PZR3-d58"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "#Memasukkan variabel2 dari proses training, menyimpan nilai akurasi val akurasi loss dan val loss\n",
        "\n",
        "epochs = range(len(acc))\n",
        "\n",
        "plt.plot(epochs, acc, 'r', label='Training accuracy')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend(loc=0)\n",
        "plt.figure()\n",
        "#Memunculkan grafik\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "cTgoOezq-Y0e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "f, ax = plt.subplots()\n",
        "ax.plot([None] + history.history['loss'], 'o-')\n",
        "ax.plot([None] + history.history['val_loss'], 'x-')\n",
        "# Plot legend and use the best location automatically: loc = 0.\n",
        "ax.legend(['Train Loss', 'Validation Loss'], loc = 0)\n",
        "ax.set_title('Training/Validation Loss per Epoch')\n",
        "ax.set_xlabel('Epoch')\n",
        "ax.set_ylabel('Loss')\n"
      ],
      "metadata": {
        "id": "vNnMVHbo-uN3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "predict = ResNet.predict(ujiX) #Mendapatkan hasil prediksi dari model\n",
        "rounded_pred=np.argmax(predict, axis=1) #Merubah dimensi\n",
        "rounded_ujiY=np.argmax(ujiY, axis=1) #Merubah dimensi\n",
        "print(confusion_matrix(rounded_ujiY, rounded_pred))\n"
      ],
      "metadata": {
        "id": "vmRRT10t-xcI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "\n",
        "def plot_confusion_matrix(cm,\n",
        "                          target_names=kelas_asli,\n",
        "                          title='Confusion matrix',\n",
        "                          cmap=None,\n",
        "                          normalize=True):\n",
        "    \"\"\"\n",
        "    given a sklearn confusion matrix (cm), make a nice plot\n",
        "\n",
        "    Arguments\n",
        "    ---------\n",
        "    cm:           confusion matrix from sklearn.metrics.confusion_matrix\n",
        "\n",
        "    target_names: given classification classes such as [0, 1, 2]\n",
        "                  the class names, for example: ['high', 'medium', 'low']\n",
        "\n",
        "    title:        the text to display at the top of the matrix\n",
        "\n",
        "    cmap:         the gradient of the values displayed from matplotlib.pyplot.cm\n",
        "                  see http://matplotlib.org/examples/color/colormaps_reference.html\n",
        "                  plt.get_cmap('jet') or plt.cm.Blues\n",
        "\n",
        "    normalize:    If False, plot the raw numbers\n",
        "                  If True, plot the proportions\n",
        "\n",
        "    Usage\n",
        "    -----\n",
        "    plot_confusion_matrix(cm           = cm,                  # confusion matrix created by\n",
        "                                                              # sklearn.metrics.confusion_matrix\n",
        "                          normalize    = True,                # show proportions\n",
        "                          target_names = y_labels_vals,       # list of names of the classes\n",
        "                          title        = best_estimator_name) # title of graph\n",
        "\n",
        "    Citiation\n",
        "    ---------\n",
        "    http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html\n",
        "\n",
        "    \"\"\"\n",
        "    import matplotlib.pyplot as plt\n",
        "    import numpy as np\n",
        "    import itertools\n",
        "\n",
        "    accuracy = np.trace(cm) / float(np.sum(cm))\n",
        "    misclass = 1 - accuracy\n",
        "\n",
        "    if cmap is None:\n",
        "        cmap = plt.get_cmap('Blues')\n",
        "\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    if normalize:\n",
        "      plt.imshow(cm/7, interpolation='nearest', cmap=cmap)\n",
        "    else:\n",
        "      plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "\n",
        "    if target_names is not None:\n",
        "        tick_marks = np.arange(len(target_names))\n",
        "        plt.xticks(tick_marks, target_names, rotation=45)\n",
        "        plt.yticks(tick_marks, target_names)\n",
        "\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "\n",
        "\n",
        "    thresh = cm.max() / 1.5 if normalize else cm.max() / 2\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        if normalize:\n",
        "            plt.text(j, i, \"{:0.3f}\".format(cm[i, j]),\n",
        "                     horizontalalignment=\"center\",\n",
        "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "        else:\n",
        "            plt.text(j, i, \"{:,}\".format(cm[i, j]),\n",
        "                     horizontalalignment=\"center\",\n",
        "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label\\naccuracy={:0.4f}; misclass={:0.4f}'.format(accuracy, misclass))\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "QzpyVk_3-yNJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cm = confusion_matrix(rounded_ujiY,  rounded_pred)\n",
        "plot_confusion_matrix(cm)"
      ],
      "metadata": {
        "id": "mDFHaB0P_D52"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "FP = cm.sum(axis=0) - np.diag(cm)  \n",
        "FN = cm.sum(axis=1) - np.diag(cm)\n",
        "TP = np.diag(cm)\n",
        "TN = cm.sum() - (FP + FN + TP)\n",
        "print(FP)\n",
        "print(FN)\n",
        "print(TP)\n",
        "print(TN)"
      ],
      "metadata": {
        "id": "XKWbjuhY_iYh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}