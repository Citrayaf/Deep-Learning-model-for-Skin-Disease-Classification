{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "VVVvf1enqTo4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "94dvuaFhp_7_"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive', force_remount=True) #Link ke gdrive\n",
        "\n",
        "import sys\n",
        "sys.path.append('/content/gdrive/My Drive') #File dari gdrive ke colab\n",
        "\n",
        "import os\n",
        "os.chdir('/content/gdrive/My Drive') #working directory menjadi /content/gdrive/My Drive "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "pAwvrCz5qWvj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def unique(list1):\n",
        "    unique_list = [] #array kosong\n",
        "     \n",
        "    for x in list1:  #looping \n",
        "        if x not in unique_list: #Cek apakah ada data yang berulang atau tidak\n",
        "            unique_list.append(x)\n",
        "    return unique_list"
      ],
      "metadata": {
        "id": "MCwZ0XbGqS1r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from PIL import Image\n",
        "from imutils import paths\n",
        "\n",
        "\n",
        "kumpl_gmbr = [] #dataset gambar\n",
        "kumpl_lbl = [] #label dataset\n",
        "imgpths = paths.list_images('Dataset') #path untuk mengambil dataset\n",
        "\n",
        "for dirimg in imgpths: #looping gambar\n",
        "  gmbr = Image.open(dirimg)\n",
        "  gmbrz = np.array(gmbr.resize((224,224))) / 255.0 #resize + normalisasi\n",
        "  kumpl_gmbr.append(gmbrz) #memasukkan dataset yang sudah diolah ke variabel\n",
        "\n",
        "  lbl_kls = dirimg.split(os.path.sep) [-2] #pengambilan label\n",
        "  kumpl_lbl.append(lbl_kls) #mengumpulkan label ke variabel\n",
        "  \n",
        "kelas_asli = unique(kumpl_lbl)\n",
        "kelas_asli"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UIxe-WOtqZZb",
        "outputId": "9ade7cb6-99ee-40c8-e70b-054c03a66b8a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelBinarizer\n",
        "\n",
        "lb = LabelBinarizer() #function untuk mengubah variabel label menjadi bentuk binary\n",
        "kumpl_lbl = lb.fit_transform(kumpl_lbl) #proses pengubahan\n",
        "#if len(kelas_asli)==2: \n",
        "#  kumpl_lbl = np.hstack((kumpl_lbl, 1 - kumpl_lbl))"
      ],
      "metadata": {
        "id": "nsAiuCVcrWat"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "ratio_latih = 0.8 #ratio data latih\n",
        "ratio_uji = 0.2 #ratio data uji\n",
        " \n",
        "(latihX, ujiX, latihY, ujiY) = train_test_split(np.array(kumpl_gmbr),np.array(kumpl_lbl), test_size=ratio_uji) #Proses pemisahan, test_size menentukan banyaknya data uji\n",
        "\n",
        "print(latihX.shape)\n",
        "print(latihY.shape)\n",
        "print(ujiX.shape)\n",
        "print(ujiY.shape)\n"
      ],
      "metadata": {
        "id": "JC8rG6PsrjCo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "RcZG7g_GsDjL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "datagen = ImageDataGenerator(\n",
        "      rotation_range=40,\n",
        "      width_shift_range=0.2,\n",
        "      height_shift_range=0.2,\n",
        "      shear_range=0.2,\n",
        "      zoom_range=0.2,\n",
        "      horizontal_flip=True,\n",
        "      fill_mode='nearest')"
      ],
      "metadata": {
        "id": "wsQSsFa_sAfD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "AksZ_iHGsL7J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "i=0\n",
        "banyak_lth=latihX.shape\n",
        "aug=[]\n",
        "for jj in range(banyak_lth[0]):\n",
        "  x = latihX[jj]\n",
        "  x = x.reshape((1,) + x.shape)  #Penambahan dimensi agar bisa diaugmentasi\n",
        "\n",
        "  for aug in datagen.flow(x, batch_size=1): #proses augmentasi, memasukkan gambar ke function augmentasi\n",
        "      latihX = np.append(latihX, aug ,axis=0)\n",
        "      label = latihY[jj]  #Pengambilan label untuk data augmentasi\n",
        "      label = label.reshape((1,) + label.shape) \n",
        "      latihY = np.append(latihY, label,axis=0)  #Memasukkan label data augment ke variabel label\n",
        "      if i == 1:\n",
        "        break \n",
        "      i += 1"
      ],
      "metadata": {
        "id": "vadnIgO5sMcC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pembentukkan Model ResNet"
      ],
      "metadata": {
        "id": "oa1r-GJIs1rX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Library\n",
        "from keras.layers import Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPooling2D\n",
        "from keras.initializers import glorot_uniform\n",
        "from keras.models import Model"
      ],
      "metadata": {
        "id": "eghmUuTSuI-e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Deklarasi Function"
      ],
      "metadata": {
        "id": "zzmauiRYs4B5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def identity_block(X, f, filters, stage, block):\n",
        "    \n",
        "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
        "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
        "    \n",
        "    F1, F2, F3 = filters\n",
        "    \n",
        "    X_shortcut = X\n",
        "    \n",
        "    X = Conv2D(filters = F1, kernel_size = (1, 1), strides = (1,1), padding = 'valid', name = conv_name_base + '2a', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = bn_name_base + '2a')(X)\n",
        "    X = Activation('relu')(X)\n",
        "\n",
        "    X = Conv2D(filters = F2, kernel_size = (f, f), strides = (1,1), padding = 'same', name = conv_name_base + '2b', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = bn_name_base + '2b')(X)\n",
        "    X = Activation('relu')(X)\n",
        "\n",
        "    X = Conv2D(filters = F3, kernel_size = (1, 1), strides = (1,1), padding = 'valid', name = conv_name_base + '2c', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = bn_name_base + '2c')(X)\n",
        "\n",
        "    X = Add()([X, X_shortcut])\n",
        "    X = Activation('relu')(X)\n",
        "    \n",
        "    return X"
      ],
      "metadata": {
        "id": "tD0DtvpwsT4Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def convolutional_block(X, f, filters, stage, block, s = 2):\n",
        "    \n",
        "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
        "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
        "    \n",
        "    F1, F2, F3 = filters\n",
        "    \n",
        "    X_shortcut = X\n",
        "\n",
        "    X = Conv2D(F1, (1, 1), strides = (s,s), name = conv_name_base + '2a', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = bn_name_base + '2a')(X)\n",
        "    X = Activation('relu')(X)\n",
        "\n",
        "    X = Conv2D(filters = F2, kernel_size = (f, f), strides = (1,1), padding = 'same', name = conv_name_base + '2b', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = bn_name_base + '2b')(X)\n",
        "    X = Activation('relu')(X)\n",
        "\n",
        "    X = Conv2D(filters = F3, kernel_size = (1, 1), strides = (1,1), padding = 'valid', name = conv_name_base + '2c', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = bn_name_base + '2c')(X)\n",
        "\n",
        "    X_shortcut = Conv2D(filters = F3, kernel_size = (1, 1), strides = (s,s), padding = 'valid', name = conv_name_base + '1', kernel_initializer = glorot_uniform(seed=0))(X_shortcut)\n",
        "    X_shortcut = BatchNormalization(axis = 3, name = bn_name_base + '1')(X_shortcut)\n",
        "\n",
        "    X = Add()([X, X_shortcut])\n",
        "    X = Activation('relu')(X)\n",
        "    \n",
        "    return X"
      ],
      "metadata": {
        "id": "GM9BKXWKtTa1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def ResNet50(input_shape=(224, 224, 3), classes=kelas_asli):\n",
        "\n",
        "    X_input = Input(input_shape)\n",
        "\n",
        "    X = ZeroPadding2D((3, 3))(X_input)\n",
        "\n",
        "    # Stage 1\n",
        "    X = Conv2D(64, (7, 7), strides=(2, 2), name='conv1', kernel_initializer=glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis=3, name='bn_conv1')(X)\n",
        "    X = Activation('relu')(X)\n",
        "    X = MaxPooling2D((3, 3), strides=(2, 2))(X)\n",
        "\n",
        "    # Stage 2\n",
        "    X = convolutional_block(X, f=3, filters=[64, 64, 256], stage=2, block='a', s=1)\n",
        "    X = identity_block(X, 3, [64, 64, 256], stage=2, block='b')\n",
        "    X = identity_block(X, 3, [64, 64, 256], stage=2, block='c')\n",
        "\n",
        "\n",
        "    # Stage 3 \n",
        "    X = convolutional_block(X, f = 3, filters = [128, 128, 512], stage = 3, block='a', s = 2)\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=3, block='b')\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=3, block='c')\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=3, block='d')\n",
        "\n",
        "    # Stage 4 \n",
        "    X = convolutional_block(X, f = 3, filters = [256, 256, 1024], stage = 4, block='a', s = 2)\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='b')\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='c')\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='d')\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='e')\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='f')\n",
        "\n",
        "    # Stage 5 \n",
        "    X = convolutional_block(X, f = 3, filters = [512, 512, 2048], stage = 5, block='a', s = 2)\n",
        "    X = identity_block(X, 3, [512, 512, 2048], stage=5, block='b')\n",
        "    X = identity_block(X, 3, [512, 512, 2048], stage=5, block='c')\n",
        "\n",
        "    # AVGPOOL \n",
        "    X = AveragePooling2D((2,2), name=\"avg_pool\")(X)\n",
        "\n",
        "    ### END CODE HERE ###\n",
        "\n",
        "    # output layer\n",
        "    X = Flatten()(X)\n",
        "    X = Dense(classes, activation='softmax', name='fc' + str(classes), kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    \n",
        "    \n",
        "    # Create model\n",
        "    model = Model(inputs = X_input, outputs = X, name='ResNet50')\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "9Pm4oo4Vubjh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ResNet = ResNet50(input_shape = (224, 224, 3), classes = kelas_asli)\n"
      ],
      "metadata": {
        "id": "Y5zSb6gewF9b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "12qPRnWJwSbs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.optimizers import SGD, Adam,  Nadam,  Adamax\n",
        "\n",
        "sgd = SGD(learning_rate=0.0015) \n",
        "adam = Adam(learning_rate=0.0015)\n",
        "nadam = Nadam(learning_rate=0.0015)\n",
        "adamax = Adamax(learning_rate=0.0015)"
      ],
      "metadata": {
        "id": "SJKDQTaAwYnt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "DdaVZXC2yY-Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "class myCallback(tf.keras.callbacks.Callback): \n",
        "    def on_epoch_end(self, epoch, logs={}): \n",
        "        if(logs.get('val_accuracy') > 0.9):   \n",
        "          print(\"\\nReached Target\")   \n",
        "          self.model.stop_training = True"
      ],
      "metadata": {
        "id": "r76Y9SIPyYIn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ResNet.compile(loss=\"categorical_crossentropy\", optimizer=adam, metrics=[\"accuracy\"])\n"
      ],
      "metadata": {
        "id": "5HGexF7Fwm5n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "buW9msN7ylsL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "callbacks = myCallback()\n",
        "history = ResNet.fit(latihX, latihY,validation_data=(ujiX, ujiY), epochs = 55, batch_size = 32, callbacks=[callbacks]) #early stopping\n",
        "#history = ResNet.fit(latihX, latihY,validation_data=(ujiX, ujiY), epochs = 55, batch_size = 32) #tanpa early stopping"
      ],
      "metadata": {
        "id": "Uw_8tPckyzSU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#evaluasi\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "print(\"[INFO] evaluating network...\")\n",
        "predictions = ResNet.predict(ujiX, batch_size=32) \n",
        "print(classification_report(ujiY.argmax(axis=1), predictions.argmax(axis=1), target_names=lb.classes_))  "
      ],
      "metadata": {
        "id": "9IaFICU4y9qt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "B6m6PZR3-d58"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "#Memasukkan variabel2 dari proses training, menyimpan nilai akurasi val akurasi loss dan val loss\n",
        "\n",
        "epochs = range(len(acc))\n",
        "\n",
        "plt.plot(epochs, acc, 'r', label='Training accuracy')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend(loc=0)\n",
        "plt.figure()\n",
        "#Memunculkan grafik\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "cTgoOezq-Y0e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "f, ax = plt.subplots()\n",
        "ax.plot([None] + history.history['loss'], 'o-')\n",
        "ax.plot([None] + history.history['val_loss'], 'x-')\n",
        "# Plot legend and use the best location automatically: loc = 0.\n",
        "ax.legend(['Train Loss', 'Validation Loss'], loc = 0)\n",
        "ax.set_title('Training/Validation Loss per Epoch')\n",
        "ax.set_xlabel('Epoch')\n",
        "ax.set_ylabel('Loss')\n"
      ],
      "metadata": {
        "id": "vNnMVHbo-uN3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "predict = ResNet.predict(ujiX) #Mendapatkan hasil prediksi dari model\n",
        "rounded_pred=np.argmax(predict, axis=1) #Merubah dimensi\n",
        "rounded_ujiY=np.argmax(ujiY, axis=1) #Merubah dimensi\n",
        "print(confusion_matrix(rounded_ujiY, rounded_pred))\n"
      ],
      "metadata": {
        "id": "vmRRT10t-xcI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "\n",
        "def plot_confusion_matrix(cm,\n",
        "                          target_names=kelas_asli,\n",
        "                          title='Confusion matrix',\n",
        "                          cmap=None,\n",
        "                          normalize=True):\n",
        "    \"\"\"\n",
        "    given a sklearn confusion matrix (cm), make a nice plot\n",
        "\n",
        "    Arguments\n",
        "    ---------\n",
        "    cm:           confusion matrix from sklearn.metrics.confusion_matrix\n",
        "\n",
        "    target_names: given classification classes such as [0, 1, 2]\n",
        "                  the class names, for example: ['high', 'medium', 'low']\n",
        "\n",
        "    title:        the text to display at the top of the matrix\n",
        "\n",
        "    cmap:         the gradient of the values displayed from matplotlib.pyplot.cm\n",
        "                  see http://matplotlib.org/examples/color/colormaps_reference.html\n",
        "                  plt.get_cmap('jet') or plt.cm.Blues\n",
        "\n",
        "    normalize:    If False, plot the raw numbers\n",
        "                  If True, plot the proportions\n",
        "\n",
        "    Usage\n",
        "    -----\n",
        "    plot_confusion_matrix(cm           = cm,                  # confusion matrix created by\n",
        "                                                              # sklearn.metrics.confusion_matrix\n",
        "                          normalize    = True,                # show proportions\n",
        "                          target_names = y_labels_vals,       # list of names of the classes\n",
        "                          title        = best_estimator_name) # title of graph\n",
        "\n",
        "    Citiation\n",
        "    ---------\n",
        "    http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html\n",
        "\n",
        "    \"\"\"\n",
        "    import matplotlib.pyplot as plt\n",
        "    import numpy as np\n",
        "    import itertools\n",
        "\n",
        "    accuracy = np.trace(cm) / float(np.sum(cm))\n",
        "    misclass = 1 - accuracy\n",
        "\n",
        "    if cmap is None:\n",
        "        cmap = plt.get_cmap('Blues')\n",
        "\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    if normalize:\n",
        "      plt.imshow(cm/7, interpolation='nearest', cmap=cmap)\n",
        "    else:\n",
        "      plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "\n",
        "    if target_names is not None:\n",
        "        tick_marks = np.arange(len(target_names))\n",
        "        plt.xticks(tick_marks, target_names, rotation=45)\n",
        "        plt.yticks(tick_marks, target_names)\n",
        "\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "\n",
        "\n",
        "    thresh = cm.max() / 1.5 if normalize else cm.max() / 2\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        if normalize:\n",
        "            plt.text(j, i, \"{:0.3f}\".format(cm[i, j]),\n",
        "                     horizontalalignment=\"center\",\n",
        "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "        else:\n",
        "            plt.text(j, i, \"{:,}\".format(cm[i, j]),\n",
        "                     horizontalalignment=\"center\",\n",
        "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label\\naccuracy={:0.4f}; misclass={:0.4f}'.format(accuracy, misclass))\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "QzpyVk_3-yNJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cm = confusion_matrix(rounded_ujiY,  rounded_pred)\n",
        "plot_confusion_matrix(cm)"
      ],
      "metadata": {
        "id": "mDFHaB0P_D52"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "FP = cm.sum(axis=0) - np.diag(cm)  \n",
        "FN = cm.sum(axis=1) - np.diag(cm)\n",
        "TP = np.diag(cm)\n",
        "TN = cm.sum() - (FP + FN + TP)\n",
        "print(FP)\n",
        "print(FN)\n",
        "print(TP)\n",
        "print(TN)"
      ],
      "metadata": {
        "id": "XKWbjuhY_iYh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}